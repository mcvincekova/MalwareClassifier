import numpy as np  # linear algebra
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam

from SingularExperimentalFeatures.ExperimentalFeaturesExtractor.histogram_extractor import sample_histograms

BENIGN_DIR = r"D:\MalwareClassifier\Data\feature_merged_scaled\benign_features_scaled.csv"
MALICIOUS_DIR = r"D:\MalwareClassifier\Data\feature_merged_scaled\malicious_features_scaled.csv"

experimental_data = sample_histograms(BENIGN_DIR, MALICIOUS_DIR, 100000, 100000)
target = experimental_data["label"]
features = experimental_data.drop("label", axis=1)

X_features = np.array(features)
Y_labels = np.array(target)

padding = np.array([0] * 20)
X_features_complete = np.empty([200000, 1024])
for i in range(len(X_features)):
    X_features_complete[i] = np.append(X_features[i], padding)

X_train, X_test, Y_train, Y_test = train_test_split(X_features_complete, Y_labels, test_size=0.20, shuffle=True)
X_train = X_train.reshape(X_train.shape[0], 32, 32, 1)
X_test = X_test.reshape(X_test.shape[0], 32, 32, 1)

model = Sequential()
# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.
# this applies 32 convolution filters of size 3x3 each.
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(32, activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(1, activation='softmax'))

model.build()
model.summary()

# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)
model.compile(loss='mean_squared_error', optimizer=adam, metrics=['accuracy'])

model.fit(x=X_train,
          y=Y_train,
          batch_size=128,
          epochs=20,
          steps_per_epoch=1000,
          validation_data=(X_test, Y_test),
          verbose=1)

score = model.evaluate(X_test, Y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

# model.fit(X_train, Y_train, batch_size=32, epochs=10)
# score = model.evaluate(X_test, Y_test, batch_size=32)
